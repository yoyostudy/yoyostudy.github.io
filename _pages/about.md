---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

My research interest includes Trustworthy AI. 

# ğŸ”¥ News
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ . 


# ğŸ“ Publications 

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">IEEE BigData 2024</div>
      <img src='images/autored_thumb.png' alt="AutoRed thumbnail" width="100%">
    </div>
  </div>

  <div class='paper-box-text' markdown="1">
  [**AutoRed: Automated Attack Scenario Generation Framework for Red Teaming of LLMs**](https://ieeexplore.ieee.org/document/10408347)  
  **Zhe Wang**, M. A. Tayebi  

  [**Citation**](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UjG0jpQAAAAJ&citation_for_view=UjG0jpQAAAAJ:XXXX)  
  <strong><span class='show_paper_citations' data='UjG0jpQAAAAJ:XXXX'></span></strong>

  - We present **AutoRed**, a framework that generates diverse adversarial prompts to evaluate LLM defenses across 100+ strategies, achieving up to 80% success.
  </div>
</div>


# ğŸ– Honors and Awards
- *2017.10* Awarded **First Prize** in the **Zhoushan Regional Round** of the **Chinese National High School Mathematics Olympiad (Zhejiang Province)**.

# ğŸ“– Educations
- *2022.09 - 2024.9*, Simon Fraser Univeristy 
- *2018.09 - 2022.07*, The Chinese University of Hong Kong, shenzhen. 

# ğŸ’¬ Invited Talks
- *2025.09*, AI lunch and learn at SAP Canada, Vancouver office. 

# ğŸ’» Internships
- *2024.09 - now*, SAP, Canada.
- *2023.07 - 2023.09*, [Hanglok-Tech](https://www.hanglok-tech.cn/), China
